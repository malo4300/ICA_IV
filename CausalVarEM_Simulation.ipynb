{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test how hard one can infer with the VarEM Alogrithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ICA_EM import *\n",
    "from models.dgp import *\n",
    "from models.metrics import *\n",
    "import importlib, sys\n",
    "importlib.reload(sys.modules['models.ICA_EM'])\n",
    "importlib.reload(sys.modules['models.dgp'])\n",
    "importlib.reload(sys.modules['models.metrics'])\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalVarEM(VarEM):\n",
    "    def __init__(self, update_sigma=False, true_A=None, tol=1e-4, mode = \"init\", **kwargs):\n",
    "        if mode not in [\"init\", \"each\"]:\n",
    "            raise ValueError(\"mode must be either 'init' or 'each'\")\n",
    "        self.mode = mode\n",
    "        super().__init__(update_sigma=update_sigma, true_A=true_A, tol=tol, **kwargs)\n",
    "    \n",
    "    def update_A(self): # we can force causal structure \n",
    "        temp1 = np.zeros((self.I, self.J))\n",
    "        temp2 = np.zeros((self.J, self.J))\n",
    "\n",
    "        for i in range(self.n):\n",
    "            omega_i = self._omega_mat(i)\n",
    "            M_i = self._M_mat(omega_i)\n",
    "            x_outer = np.outer(self.X[i,:], self.X[i,:])\n",
    "            temp1 += x_outer @ M_i.T @ self.A @ omega_i\n",
    "            temp2 += omega_i @ (np.eye(self.J) - self.A.T @ M_i @ (np.eye(self.I) - x_outer @ M_i.T) @ self.A @ omega_i)\n",
    "            self._update_xi(i, M_i, omega_i, x_outer)\n",
    "        A_new = temp1 @ np.linalg.inv(temp2)\n",
    "        if self.update_sigma:\n",
    "            self._update_sigma(A_new)\n",
    "\n",
    "\n",
    "        # calculate the difference between the old and new A\n",
    "        diff = np.linalg.norm(self.A - A_new, ord='fro')\n",
    "        self.A = A_new\n",
    "        if self.mode == \"each\":\n",
    "            self._enforce_causal_structure()\n",
    "        return diff\n",
    "    \n",
    "    def _initilize_A(self):\n",
    "        super()._initilize_A()\n",
    "        self._enforce_causal_structure()\n",
    "        \n",
    "    def _enforce_causal_structure(self):\n",
    "        self.A[0,1] = 0\n",
    "        # set ones\n",
    "        self.A[0,0] = 1\n",
    "        self.A[1,1] = 1\n",
    "        # set controls to 1\n",
    "        for j in range(2, self.J-1):\n",
    "            self.A[j,j+1] = 1\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simulation to test if we should enforce causal strucutre each time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "J = 6\n",
    "I = 5\n",
    "f_score_init = []\n",
    "f_score_each = []\n",
    "mean_squared_error_init = []\n",
    "mean_squared_error_each = []\n",
    "ll_score_init = []\n",
    "ll_score_each = []\n",
    "data = dgp(prior={\"loc\" : 0, \"scale\" : 1}, noise_dict=  {\"loc\" : 0, \"scale\" : 1})\n",
    "for i in tqdm.tqdm(range(100)):\n",
    "    data.generate_data(n=n, J=J, I=I, random_state=i)\n",
    "    CausalVarEM_est = CausalVarEM(update_sigma=False,   true_A= data.mixing_matrix_observed, tol=1e-4, max_iter=200, random_seed=1)\n",
    "    CausalVarEM_est.fit(data.data_observed, J = J,\n",
    "                      noise_params= {\"mean\" : 0, \"std\" : 1}, progress_bar= False)\n",
    "    best_perm, score = f_score(data.mixing_matrix_observed, CausalVarEM_est.A)\n",
    "    f_score_init.append(score)\n",
    "    singals_estimation_VAR = CausalVarEM_est.Signals[:,best_perm]\n",
    "    mean_squared_error_init.append(mean_squared_error(data.signals, singals_estimation_VAR))\n",
    "    ll_score_init.append(likelihood_score(data.signals, singals_estimation_VAR, normalize=True))\n",
    "\n",
    "    CausalVarEM_est = CausalVarEM(update_sigma=False,   true_A= data.mixing_matrix_observed, tol=1e-4, max_iter=200, random_seed=1, mode = \"each\")\n",
    "    CausalVarEM_est.fit(data.data_observed, J = J,\n",
    "                      noise_params= {\"mean\" : 0, \"std\" : 1}, progress_bar= False)\n",
    "    best_perm, score = f_score(data.mixing_matrix_observed, CausalVarEM_est.A)\n",
    "    f_score_each.append(score)\n",
    "    singals_estimation_VAR = CausalVarEM_est.Signals[:,best_perm]\n",
    "    mean_squared_error_each.append(mean_squared_error(data.signals, singals_estimation_VAR))\n",
    "    ll_score_each.append(likelihood_score(data.signals, singals_estimation_VAR, normalize=True))\n",
    "\n",
    "df = pd.DataFrame({\"f_score_init\" : f_score_init, \n",
    "                   \"f_score_each\" : f_score_each, \n",
    "                   \"mean_squared_error_init\" : mean_squared_error_init, \n",
    "                   \"mean_squared_error_each\" : mean_squared_error_each,\n",
    "                     \"ll_score_init\" : ll_score_init, \n",
    "                     \"ll_score_each\" : ll_score_each})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"causal_var_em.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27812231151864436\n",
      "0.2542127342996154\n",
      "2.2728058986666304\n",
      "2.234741965689394\n",
      "-16974.63876306609\n",
      "-16868.131222358497\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"causal_var_em.csv\")\n",
    "print(np.mean(df[\"f_score_init\"]))\n",
    "print(np.mean(df[\"f_score_each\"]))\n",
    "print(np.mean(df[\"mean_squared_error_init\"]))\n",
    "print(np.mean(df[\"mean_squared_error_each\"]))\n",
    "print(np.mean(df[\"ll_score_init\"]))\n",
    "print(np.mean(df[\"ll_score_each\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.          0.03072089  1.81839433  1.33629591 -0.01950924]\n",
      " [-0.12733234  1.          2.64990201  5.95097564  0.73355873 -3.35828207]\n",
      " [ 0.27678069 -0.66341626  0.21044294  1.          0.12016491 -0.03726325]\n",
      " [-0.68615179  0.08568726 -0.12411821  2.57747404  1.         -2.37739893]\n",
      " [ 0.11327235 -0.38141922  0.43771474 -0.135203    0.11581481  1.        ]]\n",
      "[[ 1.          0.         -0.35488582  2.04214999  0.          0.        ]\n",
      " [ 0.11673458  1.          1.9391092   5.45405203  1.36547065 -3.74196467]\n",
      " [-0.         -0.         -0.          1.         -0.         -0.        ]\n",
      " [ 0.          0.          0.          2.19440138  1.         -2.71822918]\n",
      " [ 0.          0.          0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(CausalVarEM_est.A)\n",
    "print(data.mixing_matrix_observed)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
